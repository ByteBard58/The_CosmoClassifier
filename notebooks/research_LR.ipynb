{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d689398c",
   "metadata": {},
   "source": [
    "# The CosmoClassifier\n",
    "In this project, I have used the Data Release 18 version of Sloan Digital Sky Survey (SDSS) dataset to train a classifier algorithm to predict whether the given credentials corresponds to a Galaxy(class 0), Star(class 1) or Quasar(class 2). This notebook is used as a playground to test different hyperparameter settings as well as preprocessing approaches. \n",
    "\n",
    "We will 4 different classifier algorithms to test the results and select the one which offers the best result. These are:\n",
    "1. Random Forest \n",
    "2. Logistic Regression **(This File)**\n",
    "3. Suppor Vector Classifier (with RBF kerel)\n",
    "\n",
    "The models are implemented in separate `.ipynb` files to avoid confusion in one notebook. You can find them all in the `notebooks` subdirectory.\n",
    "   \n",
    "We will also use 2 different dimensionality reduction techniques, which include:\n",
    "1. Linear Discriminant Analysis (LDA)\n",
    "2. Principle Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347159a",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c81e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score,KFold,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6be20",
   "metadata": {},
   "source": [
    "## Basic Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf3bf1",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbf4bead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['objid', 'specobjid', 'ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'run',\n",
       "       'rerun', 'camcol', 'field', 'plate', 'mjd', 'fiberid', 'petroRad_u',\n",
       "       'petroRad_g', 'petroRad_i', 'petroRad_r', 'petroRad_z', 'petroFlux_u',\n",
       "       'petroFlux_g', 'petroFlux_i', 'petroFlux_r', 'petroFlux_z',\n",
       "       'petroR50_u', 'petroR50_g', 'petroR50_i', 'petroR50_r', 'petroR50_z',\n",
       "       'psfMag_u', 'psfMag_r', 'psfMag_g', 'psfMag_i', 'psfMag_z', 'expAB_u',\n",
       "       'expAB_g', 'expAB_r', 'expAB_i', 'expAB_z', 'redshift', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv(\"Datasets/SDSS_DR18.csv\")\n",
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c201af",
   "metadata": {},
   "source": [
    "Dropping the identifier columns which may lead to data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3376723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.drop(columns=[\"objid\", \"specobjid\", \"run\", \"rerun\", \"camcol\", \"field\", \"plate\", \"mjd\", \"fiberid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89665e6",
   "metadata": {},
   "source": [
    "Identifying and mapping the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc3c7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "GALAXY    52343\n",
      "STAR      37232\n",
      "QSO       10425\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_raw[\"class\"].value_counts())\n",
    "df_1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "323fb64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    0\n",
       "8    0\n",
       "9    1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1[\"class\"] = df_1[\"class\"].map({\n",
    "  \"GALAXY\":0,\n",
    "  \"STAR\":1,\n",
    "  \"QSO\":2\n",
    "})\n",
    "df_1[\"class\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd0660",
   "metadata": {},
   "source": [
    "Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3edb7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ra     dec    u      g      r      i      z      petroRad_u  petroRad_g  petroRad_i  petroRad_r  petroRad_z  petroFlux_u  petroFlux_g  petroFlux_i  petroFlux_r  petroFlux_z  petroR50_u  petroR50_g  petroR50_i  petroR50_r  petroR50_z  psfMag_u  psfMag_r  psfMag_g  psfMag_i  psfMag_z  expAB_u  expAB_g  expAB_r  expAB_i  expAB_z  redshift  class\n",
       "False  False  False  False  False  False  False  False       False       False       False       False       False        False        False        False        False        False       False       False       False       False       False     False     False     False     False     False    False    False    False    False    False     False    100000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004f96e",
   "metadata": {},
   "source": [
    "No null values were found, so we are going to skip dropping nulls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd852f",
   "metadata": {},
   "source": [
    "Copying the dataset and specifying the target & feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "004ddce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1.copy()\n",
    "y = df.iloc[:,-1]      # Target Column\n",
    "x = df.iloc[:,:-1]     # Feature Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5323c",
   "metadata": {},
   "source": [
    "## ML Preprocessing, Model training, Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3344718d",
   "metadata": {},
   "source": [
    "Performing train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a8c59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=2/10,random_state=120,shuffle=True,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26187142",
   "metadata": {},
   "source": [
    "Building Pipeline (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64208f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97348053 0.97083971 0.97308973]\n",
      "Average = 0.972469989894595\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(\n",
    "  C=0.001,penalty=\"l2\",solver=\"saga\",\n",
    "  class_weight=\"balanced\",random_state=191,max_iter=10_000,n_jobs=-1)\n",
    "pca = PCA(n_components=20,random_state=69)\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "  (\"imputation\",SimpleImputer(strategy=\"median\")),\n",
    "  (\"scale\", StandardScaler()),\n",
    "  (\"pca\",pca)\n",
    "])\n",
    "pipe = Pipeline([\n",
    "  (\"preprocessor\",preprocessor),\n",
    "  (\"model\",lr_model)\n",
    "])\n",
    "\n",
    "kfold = KFold(n_splits=3,shuffle=True,random_state=10)\n",
    "score = cross_val_score(pipe,x,y,cv=kfold)\n",
    "print(score)\n",
    "print(f\"Average = {score.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07541ec8",
   "metadata": {},
   "source": [
    "Building Pipeline (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e98d1f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98341033 0.98286983 0.98346983]\n",
      "Average = 0.983249998396666\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(\n",
    "  C=0.001,penalty=\"l2\",solver=\"saga\",\n",
    "  class_weight=\"balanced\",random_state=191,max_iter=10_000,n_jobs=-1)\n",
    "lda = LDA(n_components=2)    \n",
    "# There are only 2 possible values(1,2) for n_components since there are only 3 classes. \n",
    "# n_components=2 gave much better score, so I kept that \n",
    "\n",
    "preprocessor = Pipeline([\n",
    "  (\"imputation\",SimpleImputer(strategy=\"median\")),\n",
    "  (\"scale\", StandardScaler()),\n",
    "  (\"lda\",lda)\n",
    "])\n",
    "pipe = Pipeline([\n",
    "  (\"preprocessor\",preprocessor),\n",
    "  (\"model\",lr_model)\n",
    "])\n",
    "\n",
    "kfold = KFold(n_splits=3,shuffle=True,random_state=10)\n",
    "score = cross_val_score(pipe,x,y,cv=kfold)\n",
    "print(score)\n",
    "print(f\"Average = {score.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1afbe",
   "metadata": {},
   "source": [
    "Here is the summary of the entire calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8ad60",
   "metadata": {},
   "source": [
    "| Dimensionality Reduction / Models $\\downarrow \\leftrightarrow$ | Random Forest | Support Vector Classifier | Logistic Regression |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| Principal Component Analysis | 0.9803 | 0.9471 | 0.9725 |\n",
    "| Linear Discriminant Analysis | 0.9846 | 0.9832 | 0.9832 |\n",
    "| Sequential Feature Selection | 0.9870 | Null | Null |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
