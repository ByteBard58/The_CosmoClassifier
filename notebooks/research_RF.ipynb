{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d689398c",
   "metadata": {},
   "source": [
    "# The CosmoClassifier\n",
    "In this project, I have used the Data Release 18 version of Sloan Digital Sky Survey (SDSS) dataset to train a classifier algorithm to predict whether the given credentials corresponds to a Galaxy(class 0), Star(class 1) or Quasar(class 2). This notebook is used as a playground to test different hyperparameter settings as well as preprocessing approaches. \n",
    "\n",
    "We will 4 different classifier algorithms to test the results and select the one which offers the best result. These are:\n",
    "1. Random Forest **(This File)**\n",
    "2. Logistic Regression\n",
    "3. Suppor Vector Classifier (with RBF kerel)\n",
    "\n",
    "The models are implemented in separate `.ipynb` files to avoid confusion in one notebook. You can find them all in the `notebooks` subdirectory.\n",
    "   \n",
    "We will also use 3 different dimensionality reduction techniques, which include:\n",
    "1. Sequential Feature Selection (SFS)\n",
    "2. Linear Discriminant Analysis (LDA)\n",
    "3. Principle Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347159a",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c81e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score,KFold,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6be20",
   "metadata": {},
   "source": [
    "## Basic Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf3bf1",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbf4bead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['objid', 'specobjid', 'ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'run',\n",
       "       'rerun', 'camcol', 'field', 'plate', 'mjd', 'fiberid', 'petroRad_u',\n",
       "       'petroRad_g', 'petroRad_i', 'petroRad_r', 'petroRad_z', 'petroFlux_u',\n",
       "       'petroFlux_g', 'petroFlux_i', 'petroFlux_r', 'petroFlux_z',\n",
       "       'petroR50_u', 'petroR50_g', 'petroR50_i', 'petroR50_r', 'petroR50_z',\n",
       "       'psfMag_u', 'psfMag_r', 'psfMag_g', 'psfMag_i', 'psfMag_z', 'expAB_u',\n",
       "       'expAB_g', 'expAB_r', 'expAB_i', 'expAB_z', 'redshift', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv(\"Datasets/SDSS_DR18.csv\")\n",
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c201af",
   "metadata": {},
   "source": [
    "Dropping the identifier columns which may lead to data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3376723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.drop(columns=[\"objid\", \"specobjid\", \"run\", \"rerun\", \"camcol\", \"field\", \"plate\", \"mjd\", \"fiberid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89665e6",
   "metadata": {},
   "source": [
    "Identifying and mapping the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc3c7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "GALAXY    52343\n",
      "STAR      37232\n",
      "QSO       10425\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_raw[\"class\"].value_counts())\n",
    "df_1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "323fb64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    0\n",
       "8    0\n",
       "9    1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1[\"class\"] = df_1[\"class\"].map({\n",
    "  \"GALAXY\":0,\n",
    "  \"STAR\":1,\n",
    "  \"QSO\":2\n",
    "})\n",
    "df_1[\"class\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd0660",
   "metadata": {},
   "source": [
    "Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3edb7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ra     dec    u      g      r      i      z      petroRad_u  petroRad_g  petroRad_i  petroRad_r  petroRad_z  petroFlux_u  petroFlux_g  petroFlux_i  petroFlux_r  petroFlux_z  petroR50_u  petroR50_g  petroR50_i  petroR50_r  petroR50_z  psfMag_u  psfMag_r  psfMag_g  psfMag_i  psfMag_z  expAB_u  expAB_g  expAB_r  expAB_i  expAB_z  redshift  class\n",
       "False  False  False  False  False  False  False  False       False       False       False       False       False        False        False        False        False        False       False       False       False       False       False     False     False     False     False     False    False    False    False    False    False     False    100000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004f96e",
   "metadata": {},
   "source": [
    "No null values were found, so we are going to skip dropping nulls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd852f",
   "metadata": {},
   "source": [
    "Copying the dataset and specifying the target & feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "004ddce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1.copy()\n",
    "y = df.iloc[:,-1]      # Target Column\n",
    "x = df.iloc[:,:-1]     # Feature Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5323c",
   "metadata": {},
   "source": [
    "## ML Preprocessing, Model training, Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3344718d",
   "metadata": {},
   "source": [
    "Performing train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a8c59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=2/10,random_state=120,shuffle=True,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfff51a",
   "metadata": {},
   "source": [
    "Building Pipeline (SFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10fddd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98716026 0.98649986 0.98745987]\n",
      "Average = 0.9870399987974201\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "  n_estimators=150,max_depth=10,random_state=102,class_weight=\"balanced\",n_jobs=-1)\n",
    "sfs = SequentialFeatureSelector(\n",
    "  rf_model,n_features_to_select=\"auto\",tol=0.007,direction=\"forward\",cv=None)\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "  (\"imputation\",SimpleImputer(strategy=\"median\")),\n",
    "  (\"scale\", StandardScaler()),\n",
    "  (\"sfs\",sfs)\n",
    "])\n",
    "pipe = Pipeline([\n",
    "  (\"preprocessor\",preprocessor),\n",
    "  (\"model\",rf_model)\n",
    "])\n",
    "\n",
    "kfold = KFold(n_splits=3,shuffle=True,random_state=10)\n",
    "score = cross_val_score(pipe,x,y,cv=kfold)\n",
    "print(score)\n",
    "print(f\"Average = {score.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26187142",
   "metadata": {},
   "source": [
    "Building Pipeline (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64208f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98050039 0.97929979 0.98100981]\n",
      "Average = 0.980269997696077\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "  n_estimators=150,max_depth=10,random_state=103,class_weight=\"balanced\",n_jobs=-1)\n",
    "pca = PCA(n_components=20,random_state=19)\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "  (\"imputation\",SimpleImputer(strategy=\"median\")),\n",
    "  (\"scale\", StandardScaler()),\n",
    "  (\"pca\",pca)\n",
    "])\n",
    "pipe = Pipeline([\n",
    "  (\"preprocessor\",preprocessor),\n",
    "  (\"model\",rf_model)\n",
    "])\n",
    "\n",
    "kfold = KFold(n_splits=3,shuffle=True,random_state=10)\n",
    "score = cross_val_score(pipe,x,y,cv=kfold)\n",
    "print(score)\n",
    "print(f\"Average = {score.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07541ec8",
   "metadata": {},
   "source": [
    "Building Pipeline (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e98d1f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9844  0.98478]\n",
      "Average = 0.9845900000000001\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "  n_estimators=150,max_depth=10,random_state=104,class_weight=\"balanced\",n_jobs=-1)\n",
    "lda = LDA(n_components=2)    \n",
    "# There are only 2 possible values for n_components since there are only 3 classes.  \n",
    "# n_estimaors=2 gave the best score. So I kept it for the final version\n",
    "preprocessor = Pipeline([\n",
    "  (\"imputation\",SimpleImputer(strategy=\"median\")),\n",
    "  (\"scale\", StandardScaler()),\n",
    "  (\"lda\",lda)\n",
    "])\n",
    "pipe = Pipeline([\n",
    "  (\"preprocessor\",preprocessor),\n",
    "  (\"model\",rf_model)\n",
    "])\n",
    "\n",
    "kfold = KFold(n_splits=2,shuffle=True,random_state=10)\n",
    "score = cross_val_score(pipe,x,y,cv=kfold)\n",
    "print(score)\n",
    "print(f\"Average = {score.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3c27c4",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144058b9",
   "metadata": {},
   "source": [
    "Here is a summary of the entire calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55233ef0",
   "metadata": {},
   "source": [
    "| Dimensionality Reduction / Models $\\downarrow \\leftrightarrow$ | Random Forest | Support Vector Classifier | Logistic Regression |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| Principal Component Analysis | 0.9803 | 0.9471 | 0.9725 |\n",
    "| Linear Discriminant Analysis | 0.9846 | 0.9832 | 0.9832 |\n",
    "| Sequential Feature Selection | 0.9870 | Null | Null |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd1eb1",
   "metadata": {},
   "source": [
    "From this table, we can see that Random Forest with SFS has achieved the best cross validation score overall. But, we are going to avoid it because of it's extreme complexity and inefficiency. In my Macbook Air M2, it took more than 20 minutes to run even with `n_jobs` set to -1 (all CPU cores are used)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af8214",
   "metadata": {},
   "source": [
    "So, we have fixed the Rnadom Forest model with LDA as our final version for the Web App !\n",
    "\n",
    "**BUT**, There is a catch! Check the `research_2.ipynb` file to know about it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
